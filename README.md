<h1 align="center">AtomGPT</h1>
<h4 align="center">
    <p>
        <a href="">English</a> |
        <b>中文</b>
    <p>
</h4>

### Bulb项目的愿景
在这个颠覆时代的AI技术浪潮中，国内外涌现出了一大批有影响力和代表性的大模型产品，包括但不限于OpenAI的ChatGPT、百度的文心一言、阿里的通义千问、讯飞的星火大模型，智谱AI的ChatGLM、面壁智能的面壁模方等，我们尝试和这些未来的AGI对话，去了解它们的所思所想，打破人类和AGI之间的认知隔阂。Bulb项目的名称意为“灯泡”，旨在为大型模型产品的能力边界照亮明灯，以便我们能够对它们有更具体和定量的认识。

未来，我们会不断为大模型家庭引入新的成员。为了能够更公平地去探索各个大模型的能力，我们为每个大模型起了个别名，包括：萝卜、茄子、胡萝卜、辣椒、南瓜、土豆等。

### 如何评价大模型的能力：
由于大模型在不同任务、知识上具有超强的通用能力，如何客观、准确地评价它们是一个巨大的挑战。为此，我们采取两种方式：
1. 通过OpenAI的GPT-3.5/GPT-4来评分：GPT-3.5/GPT-4是目前大家公认的能力最强的大模型，因此，我们用GPT-3.5/GPT-4来评价各个模型的问答效果。后期，我们会全部采用GPT-4进行评测。我们采用以下格式来对GPT-3.5/GPT-4提问：
```
您是一个乐于助人和准确的助理，用于检查回复具体问题的答案的质量。
[问题]：{question}
[答案]：{answer}
我们希望您对某个AI助手在上述问题的回答表现提供反馈。你将根据从0到10的评分获得总体综合表现得分，其中较高的分数表示整体表现更好。请首先输出一行单独包含一个数值，表示助手的得分。接下来的一行，请提供您评价的全面解释，避免任何潜在的偏见。
```
上面的prompt中，`{question}`和`{answer}`分别对应着被测试的问题内容和大模型的回复。我们举一个具体的例子如下：
```
您是一个乐于助人和准确的助理，用于检查回复具体问题的答案的质量。
[问题]：给出五个原创的古诗或现代诗句子。
[答案]：1. 古诗：春风又绿江南岸，明月何时照我还。\n现代诗：春风吹拂着江南岸，明月何时才能再次照亮我的心房。\n2. 古诗：山重水复疑无路，柳暗花明又一村。\n现代诗：山峦重叠，江水回旋，我心中充满了疑惑和迷茫，但是当我走过一条小巷时，眼前豁然开朗，仿佛又回到了一个美丽的村庄。\n3. 古诗：落霞与孤鹜齐飞，秋水共长天一色。\n现代诗：夕阳的余晖和孤独的野鸟一同飞翔，秋日的湖水和天空融为一体，形成了一幅壮丽的画面。\n4. 古诗：人生若只如初见，何事秋风悲画扇。\n现代诗：如果人生只是初次相见那样简单，那么为什么秋风会让人感到悲伤呢？或许是因为我们经历了太多的离别和分别。\n5. 古诗：采菊东篱下，悠然见南山。\n现代诗：在东边的篱笆下采摘着菊花，悠闲地看着南山，这是一种多么美好的生活啊！
我们希望您对某个AI助手在上述问题的回答表现提供反馈。你将根据从0到10的评分获得总体综合表现得分，其中较高的分数表示整体表现更好。请首先输出一行单独包含一个数值，表示助手的得分。接下来的行，请提供您评价的全面解释，避免任何潜在的偏见。
```

2. 通过用户的反馈来评分：在每个问题的答案下方，我们展示了不同模型的回答，用户可以“点赞”或“点踩”每个答案。我们将统计每个模型的答案得分进行评价，这是一种最为客观和准确的评价方式，但是依赖于大量的用户反馈。因此，我们欢迎每一位朋友在答案下方给出您的评价，您的反馈将影响未来AGI的发展方向。

### 从哪些方面评价大模型





